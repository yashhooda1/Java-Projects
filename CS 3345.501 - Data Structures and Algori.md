CS 3345.501 - Data Structures and Algorithms Notes

  

- effective 

- useful  

  

- efficient 

- usable 

  

Data Structures  

- Organization of the data. 

- Linear: Arrays, Linked Lists 

                - ordered, unordered 

- FIFO: Queue  

- LIFO: Stack 

- HashTable: (magic array) 

- Graph: Trees and graph algorithms 

   - Balanced Trees 

  

Algorithms 

- Operations which are performed on that stored data. 

***** - CRUD  

          - Create/Insert/Add/Push 

    - Retrieve/Search/Find 

    - Update/Modify 

    - Delete/Pop/Dequeue 

     - study the worst case time analysis 

     - use cases or business cases will dictate the required time  

      for each operation. 

  

    

Terminology 

  - Abstract Data Type (ADT) 

    - Mathematical description of a "thing" with set of operations; like a graph. 

  - Algorithm  

    - A high level, language indepedent description of a step-by-step process. 

   - Data Structure 

     - A specific organization of data and family of algorithms for implementing an ADT. 

      (used case and java case) 

   - Implementation of a data structure 

    

08/24 

- Terminology  

    - Implementation of a data structure 

      -  A specific implementation or coding in a specific  

        programming language. 

       - Trade-offs 

          -  A data structure strives to provide many useful, efficient operations. But there  

          are unavoidable trade-offs. 

         - Time vs. Space 

          - One operation more efficient if another less efficient. 

  

     - We ask 

       - Does this support the operations I need efficiently? 

       - Will it be easy to use, implement, and debug? 

       - What assumptions am I making about how my software will be used? 

       (more lookeups or more inserts) 

  

      - Array vs. Linked List 

  

Lazy Deletion - wrong class - mark property as deleted, not leaving. 

Lazy Deletion is not that effective in removing objects. We dont waste time with lazy deletion. 

1. find Big(n)  

2. Mark O(n) to mark it  

  

      K searches + (N-K)shifting = Big(N) 

  

Binary Search gives us logarithmic solutions = O(logN) by reducing problem by half 

Logarithmic growth  

  

Algorithms are two types 

Iterative 

Recursive 


We have to figure out the worst case running time on both types. 


Important Big-Oh sets 

O(1) constant 

O(logN) logarithmic 

O(sqrtN)  

O(N) - linear 

O(NlogN) 

O(N^2) 

O(N^3) 

O(2^N) 

O(e^N) 

 

  Running times in O(NlogN) or faster are considered  

efficient, whereas O(N^7) or more are usually considered  

Useless; so may or may not be considered efficient. 

 

Iterative Algorithms  

1. A() { 

	int i; 

	for (i = 1 to N) 

	print();

}  O(N)

- Nested loops are independent or dependent.

2. A() { //independent
	int i, j;
      for (i = 1 to N)
	for (j = 1 to N) // independent of i loop or outer loop?
	  print();
}	O(N^2)

3. A() {
	int i;
	for (i = 1; i^2 <= N; i++)
	print();
	} O(sqrt(N)

4. A() {
	int i;
	for (i = 1; i^2 <= N; i = i*2)
	print();
	} O(logN)

5. A() {
	i = 1, s = 1;      i = 1,2,3,4,5,6,.....k
	while (s <= n) {   s = 1,2,3,4,5,6......k
	i++;			when i reaches k, s reaches n
	s = s + i;   	s = k(k+1)/2
	print();          check it; if i=3, s = 6
}                        for the loop to stop
}	O(sqrtN)           k(k+1)/2 > n
                         k^2 + k/2 > n
                         k^2 > n



ADT Graphs
	- Set of Vs and Es
	V = {v1, v2. v3}
	E = {e1}
	e1: v1 - v2 or v1 -> v2

Unidrectional fiber
	- source - destination

Directional fiber
 A -> B Directed Graph
 A -> B -> C -> A - Cyclic graph
 A -> B -> C - Acyclic graph

DAG, could be a tree
 - A -> B and A -> C

DAG, not a tree
 A -> B and C -> B

Rooted Tree: DAG. but not all DAGs are rotted tree
- all nodes have a single parent

Binary tree - There is NO ORDER in the tree. You can randomly insert.
- Root: 0-2 children
 - Internal Node: 1 or 2 children
- Leaf: 0 children

Triary Tree (3ary)
 - Root: 0-3 children
 - Internal Node: 1-3 children
 - Leaf: 0 children

Binary Search Tree - can be lopsided in ascending or descending order.
 - Will become lopsided linked list if data comes in specific order.
 - DAG
 - Property: Order 
 - TreeNode
 - 




1.	Merging two binary min-heaps (both implemented using an array) each containing N elements into a single binary min heap. 

Explanation: The worst case time in Log(N) because each heap is very similar to a complete tree which takes Log(N) time, 
and when you merge 2 heaps into one, you are adding elements and no matter how many elements you add, the height of the tree will be Log(N). 
A heap and complete tree are fundamentally balanced, so it inserts from left to right and top to bottom. 
There is no order in complete tree as long as the tree is balanced with 2 elements per node.
 Unlike the binary tree, the min heap takes the new element and compares it with the  previous element in the tree and if the previous element is greater then the new element, 
then you swap the new element with the previous element until the lowest number reaches the top of the tree. 
There is no constraint for where the node goes in the heap. Therefore the worst case time is log(N).



Searching in a tree will always be Log(N)


ADT - Graph (Called ADT because there is a relationship among nodes and you can interpret it however you want. Vehicle -> ADT)
-> Organization -> implemented as a complete tree 
-> utilized/organized as a heap 
-> So, PQ is implemented as a heap, with data structure array. 
-> Graph is implemented as a Binary Search Tree, which is a real tree and linked list. 
-> Complete Tree is O(1) to insert. O(N) to find. 
-> Heap is O(1) to delete + log(N) to balance. 



      AVL Tree has  BST property
    -> 0, 1, 2 children
     -> Order L < P < R
     -> Detect and Balance

      Imbalanceness only happens when a node is inserted.




	4 cases
1. Left - left? - node in trouble. When node is in trouble, the trouble is from the left. The insertion happened from the left.
2. Right - right - insertion took place on the right.
3. Left - right - insertion took place on the right family on left node.
4. Right - left - insertion took place on the left family on right node.



AVL Cases


Project 10/03/2022
Insert 50-100 Nodes and detect if it is a BST or an AVL tree.

AVL code -> https://www.geeksforgeeks.org/avl-tree-set-1-insertion/

Structure - any node can have 0,1,2 children. Structure of AVL Tree is the same as the Binary Search Tree
- AVL and BST have the same structure and organization.
- AVL has an engine that detects and balances itself that BST doesn't. If we make BST, the child, it wont work. BST must be parent.
- Once the node is inserted, then BST is different.
- Complete Binary Tree has the same structure as AVL and BST. Cannot be child of BST because the organization is different, but the graphs are same. Must be itself.
- 


AVL Tree - 4 types of organization -> LL, RR, LR, RL
- First balanced tree.
- Always has log(N) height.
- Bring Log(N) closer.
- Does lazy deletion NOT deletion - marks as deleted and after a certain ratio, then it will recreate another tree without deleted node.

3 rules in AVL Tree

Project 2 - go into AVL code, spit out which insertion goes into imbalances.


Zig rotation - swapping the root. 
Zig-Zig rotation - 

Splay Tree 
	- Balanced BSTs are not necessarily optimal! 
	- Splay tree is a self-adjusting BST.
	- Delete, insert, or finding node. 
	- Why is splaying worthwhile?
	- Balanced trees like AVL are guaranteed O(logN).
	 - Claim: Depending on the access sequence, balanced BSTs may not be optimal BSTs.
	 - Note: access is the CRUD (Create, Retrieve, Update, Delete) operation.

2 rules
Implicit - insert near the root and Structure of BST

     - Static 

	- A more balanced approach
       - in 1983, .....

      - Locality
          - If an item is accessed, it is likely to be accessed again soon.
          - Assume m >= n access in a tree of size n
            - total worst case time is O(mlogn)
          - O(logn) per access amortized time. (amortized is for stuff we are accessing)
          - suppose only k distinct items are accessed in the m accesses.
           - Time is O(nlogn + mlogk)
              O(nlogn): getting those k items near the root
              O(mlogk): those k items are all at the top of the tree. 
              Will always be O(mlogk) - it is a static balanced tree.
              
	- Splay Operations: Insert
        - to insert - as a BST and then splay it to the node. 
    AVL is an intelligent BST as a balanced.
     

Red Black Trees
https://www.freecodecamp.org/news/red-black-trees/
(Self Balancing BST)

- Balanced Tree
  - Red/Black Tree properties
   1. every node is either red or black (ink availability was either red or black)
   2. the root and leaves (NIL's) are black
   3. If a node is red, then its parent is black shade.
   4. All simple paths from any node x to a descendent leaf have the same number of black shaded nodes = black-height(x).
  
- Walk through the algorithm to insert
    - available  on elearning under Learning objectives.

    https://www.cs.usfca.edu/~galles/visualization/RedBlack.html
    
2-3-4 trees removal

Graph
G = (V, E)
V = set of Vertices {V1, V2, V3,...., Vn}
E = set of Edges {e1, e2, e3, .... en}
ei = (Vj, Vk)

directed or undirected. 
A, B, or C
A, B, and C

V = {A, B, C}
E = {(A, B), (A, C), (B, A), (B, C)}

Degree of A: 3
B: 2
C: 2
D: 1

in-degree A: 1, B: 1, C: 2
out-degree A: 2, B: 2

|V| is the number of edges
|E| is the number of vertices

min # of V: 1
of E: empty set

Directed:

Undirected Graph: 
Connected -> go anywhere from any node in 1 or more loops
Fully Connected -> go from any node to any other node in 1 hop.

Directed Graph: 
Weakly Connected -> graph is connected if we remove arcs.
Strongly Connected -> go from any node to any other node.
Fully Connected -> go from any node to any other node in 1 hop.

Weakly Connected: A -> B 
Strongly Connected: A -> B -> C -> A
Fully Connected: A -> B, B -> A, A -> C, B -> C, C -> A, C -> B

Road Networks are connected and airline routes are weakly connected.

Weighted Graphs: weight associated to an edge, miles, time, input parameters, etc...

Paths and Cycles: A path is a list of vertices [v0, v1, v2, ..., vn] such that (vi, vi + 1) is in E for all 
0 <= 1 <= n

A cycle is a path that begins and ends at the same node (v0==vn)
Path length: mumber of edges
Path cost: sum of weights

A simple path repeats no vertices, except may be the first and last.
A cycle is a path that ends where it begins

A simple cycle is a cycle and simple path.

A -> B -> C
D -> C, D -> B

No path from A -> D and no cycles so the graph is Directed Acyclic Graph or DAG.

DAG (Directed Acyclic Graph)
- A DAG is a directed graph with no directed cycles. 
- Every rooted directed tree is a DAG.
- But not every DAG is a rooted directed tree.
- children with multiple parents. 
- Every DAG is a directed graph
- But not every directed graph is a DAG

ADT: Graph depicting or representing relationships.
Properties of Graphs: 
- Dense (E ~ V^2) vs. Sparse (E ~ V)

Organization: Adjacency List or Adjacency Matrix.
Implementation: Array or Linked List

Running Time (Matrix): 
- Get a vertex's out degree: O(|d|) d~E
- Get a vertex's in degree: O(|d|) if we have a list of in-edges; d~E
- Decide if some edge exists: O(1)
- Insert an edge: O(1)
- Unless finding O(d) 
- Delete an edge: O(d)

Space Requirement: O(|V| + |E|)
Best for Sparse graphs 
How can we adopt this matrix for weighted graphs?
- Replace F with -1 and 0 and T with the weight

A -> B
B -> A
C -> B -> D (C -> B & C -> D)
D -> NULL





A -> B -> A, C -> B, C -> D

Matrix
A A - F
A B - T
A C - F
A D - F
B A - T
B B - F
B C - F
B D - F
C A - F
C B - T
C C - F
C D - T
D A - F
D B - F
D C - F
D D - F





Topological Sort: Given a DAG, order all the vertices so that every vertex comes
before all its neighbors.

Shortest Path: Find the shortest or the lowest-cost path from X to Y. 
  - Related: determine if there even is such a path.

Topology - the study of geometric properties and spatial relations unaffected by change.

CS 142 -> CS 143 -> CS 374 -> xyz 
MATH 126 -> CS 143
CS 143 -> CS 373 
CS 373 -> CS 410
CS 373 -> CS 413
CS 373 -> CS 415
CS 373 -> CS 417 

Problem: Given a DAG G = (V, E), output all vertices in an order such that 
no vertex appears before another vertex that has an edge to it. For example, CS 373 cannot appear
before CS 143.

A partial order meaning there are multiple potential total topological order outputs exist. 
An example of a total order: MATH126, CS142, CS143, CS374, CS373, CS417, CS410, CS413, XYZ, CS415

Why do we perform TS only on DAGs? Because a cycle means there is not correct answer. 
- Is there always a unique answer? No, there can be 1 or more answers/outputs, depends on the graph. 
- Terminology: A DAG represents a partial order and a topological sort produces a total order that is consistent 
with it. 
- Usage/Applications: How to graduate, using a makefile, dependency graph.

A first algorithm for TS
  1. Label("mark") each vertex with its in-degree 
   - Think of writing in a field in the vertex. 
   - Could also do this via a data structure (ex. an array) on the side. 

  2. While there are vertices not yet output:
    - Choose a vertex v with labeled with in-degree of 0
    - Output v and conceptually remove it from the graph 
    - For each vertex u adjacent to v(ex. u such that (v, u) in E), decrement the in-degree of u.

  Node Array: 126 | 142 | 143 | 374 | 373 | 410 | 413 | 415 | 417 | XYZ |

  Removed?  X | x | x | x | X | x | x | x | x |

  In-degree Array: 0 | 0 | 2 | 1 | 1 | 1 | 1 | 1 | 1 | 3 |        
                          1,0  0   0   0   0   0   0   2,1,0

      Notice:
      - Needed a vertex with in-degree 0 to start
      - Will always have at least 1 because no cycles

      - Ties among vertices with in-degree of 0 can be broken arbitrarily.
      - Can be more than one correct answer, by definition depending upon the graph. 

    Running Time?
       labelEachVertexWithItsInDegree();
       for (int i = 0; i < numVertices; i++) { -> 1
        v = findNewVertexOfDegreeZero(); -> 2
        // put v next in output
        for each w adjacent to v -> 3
        w.indegree--;
       }


What is the worst case running time?
- Initialization O(|V| + |E|) (assuming adjacency list)
- Sum of all find-new-vertex O(|V|^2) -> 1 and 2 above
- Sum of all decrements O(|E|) -> 3 above
- So total is O(|V|^2)

Doing better 
The trick is to avoid searching for a zero degree node every time! 
  - Keep the "pending" zero-degree nodes in a list, stack, queue, bag, table, napkin.
  - Order we process them affects output but not correctness or efficiency provided add/remove are
  both O(1)

  Using a queue:
   1. Label each vertex with its in-degree, enqueue 0 degree nodes
   2. While queue is not empty
    a. V = dequeu()
    b. Output v and remove it from the graph
    c. For each vertex u adjacent to v (u such that (v, u) in E), decrement the in-degree of u, if
    new degree is 0, enqueue it.


    labelAllAndEnqueueZeros();
       for (int i = 0; i < numVertices; i++) { -> 1
        v = dequeue(); -> 2
        // put v next in output
        for each w adjacent to v {
        w.indegree--;
        if (w.indegree == 0)
          enqueue(v);
          }
       }

       What is the worst case running time?
       - Initialization O(|V| + |E|) (assuming adjacency list)
      - Sum of all enqueues and dequeues: O(V)
      - Sum of all decrements O(|E|) 
      - So total is O(|V| + |E|) -- much better for sparse graphs!

    Graph Traversals - Depth first search and then another search

  Next Problem: For an arbitrary graph and a starting node v, find all nodes reachable from v(there exists a path from v)
  - Do something for each node
  - print to output, set a field, etc...
   
  Subsumed problem: is an undirected graph connected?
  Related but different problem: is a directed graph strongly connected?
   - Need cycles back to starting node

  Basic Idea:
    - Keep following nodes
    - But "mark" nodes after visiting them. So the traversal terminates and processes each reachable 
    node exactly once.

  Abstract Idea:
       traverseGraph(Node start) {
        Set pending = emptySet();
        Pending.add(start)
        mark start as visited 
        While (pending != empty) {
          Next = pending.remove();
          for each node u adjacent to next
          if(u i is not marked) {
            mark u
            pending.add(u)
              }
          }
        }

        Spanning Tree - relationship of nodes without getting into cycle.
        Tree that has the mininum sum of edges is called a mininum spanning tree.
        There can be more then 1 spanning tree.

        Prim and Kruskal say that without doing try and error, you can run my algorithm and 
        there will be only 1 tree. Prim believes on removing edges that aren't required/selecting just like Dijkstra's.
        Kruskal puts the edges in order by weight and adds until it reaches n-1 and stops. Kruskal lacks the engine 
        that tells it should you add that edge or not. 
        Union Find - an algorithm that tells you by adding that edge you will get it.
        Dijkstra's is cumulative distance, prim keeps track of edge size.

        Union-Find Algorithm
        